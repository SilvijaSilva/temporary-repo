{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b261c6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello class\n"
     ]
    }
   ],
   "source": [
    "print('hello class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b29c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-openai langchain_chroma langchain_community langchainhub beautifulsoup4 bs4 rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f9ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables\n",
    "\n",
    "token = os.getenv(\"OPENAI_API_KEY\")\n",
    "endpoint = \"https://models.github.ai/inference\"\n",
    "model = \"openai/gpt-4.1-nano\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=model, base_url=endpoint, api_key=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7f05042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a914732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'An Overview of Deep Learning for Curious People\\n    \\nDate: June 21, 2017  |  Estimated </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Reading Time: 12 min  |  Author: Lilian Weng'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'(The post was originated from my talk for WiMLDS x Fintech meetup hosted by Affirm.)\\nI </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">believe many of you have watched or heard of the games between AlphaGo and professional Go player Lee Sedol in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2016. Lee has the highest rank of nine dan and many world championships. No doubt, he is one of the best Go players</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in the world, but he lost by 1-4 in this series versus AlphaGo. Before this, Go was considered to be an intractable</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">game for computers to master, as its simple rules lay out an exponential number of variations in the board </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">positions, many more than what in Chess. This event surely highlighted 2016 as a big year for AI. Because of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AlphaGo, much attention has been attracted to the progress of AI.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Meanwhile, many companies are spending resources on pushing the edges of AI applications, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that indeed have the potential to change or even revolutionize how we are gonna live. Familiar examples include </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">self-driving cars, chatbots, home assistant devices and many others. One of the secret receipts behind the progress</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">we have had in recent years is deep learning.\\nWhy Does Deep Learning Work Now?#\\nDeep learning models, in simple </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">words, are large and deep artificial neural nets. A neural network (“NN”) can be well presented in a directed </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">acyclic graph: the input layer takes in signal vectors; one or multiple hidden layers process the outputs of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">previous layer. The initial concept of a neural network can be traced back to more than half a century ago. But why</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">does it work now? Why do people start talking about them all of a sudden?'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'A three-layer artificial neural network. (Image source: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">http://cs231n.github.io/convolutional-networks/#conv)\\n\\nThe reason is surprisingly simple:\\n\\nWe have a lot more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">data.\\nWe have much powerful computers.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'A large and deep neural network has many more layers + many more nodes in each layer, which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">results in exponentially many more parameters to tune. Without enough data, we cannot learn parameters efficiently.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Without powerful computers, learning would be too slow and insufficient.\\nHere is an interesting plot presenting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the relationship between the data scale and the model performance, proposed by Andrew Ng in his “Nuts and Bolts of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Applying Deep Learning” talk. On a small dataset, traditional algorithms (Regression, Random Forests, SVM, GBM, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">etc.) or statistical learning does a great job, but once the data scale goes up to the sky, the large NN </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">outperforms others. Partially because compared to a traditional ML model, a neural network model has many more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parameters and has the capability to learn complicated nonlinear patterns. Thus we expect the model to pick the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">most helpful features by itself without too much expert-involved manual feature engineering.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The data scale versus the model performance. (Recreated based on: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://youtu.be/F1ka6a13S9I)'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Deep Learning Models#\\nNext, let’s go through a few classical deep learning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models.\\nConvolutional Neural Network#'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Convolutional neural networks, short for “CNN”, is a type of feed-forward artificial neural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">networks, in which the connectivity pattern between its neurons is inspired by the organization of the visual </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cortex system. The primary visual cortex (V1) does edge detection out of the raw visual input from the retina. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">secondary visual cortex (V2), also called prestriate cortex, receives the edge features from V1 and extracts simple</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">visual properties such as orientation, spatial frequency, and color. The visual area V4 handles more complicated </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">object attributes. All the processed visual features flow into the final logic unit, inferior temporal gyrus (IT), </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for object recognition. The shortcut between V1 and V4 inspires a special type of CNN with connections between </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">non-adjacent layers: Residual Net (He, et al. 2016) containing “Residual Block” which supports some input of one </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">layer to be passed to the component two layers later.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Illustration of the human visual cortex system. (Image source: Wang &amp; Raj </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2017)\\n\\nConvolution is a mathematical term, here referring to an operation between two matrices. The convolutional</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">layer has a fixed small matrix defined, also called kernel or filter. As the kernel is sliding, or convolving, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">across the matrix representation of the input image, it is computing the element-wise multiplication of the values </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in the kernel matrix and the original image values. Specially designed kernels can process images for common </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">purposes like blurring, sharpening, edge detection and many others, fast and efficiently.\\n\\n\\nThe LeNet </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">architecture consists of two sets of convolutional, activation, and pooling layers, followed by a fully-connected </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">layer, activation, another fully-connected layer, and finally a softmax classifier (Image source: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">http://deeplearning.net/tutorial/lenet.html)'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Convolutional and pooling (or “sub-sampling” in Fig. 4) layers act like the V1, V2 and V4 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">visual cortex units, responding to feature extraction. The object recognition reasoning happens in the later </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">fully-connected layers which consume the extracted features.\\nRecurrent Neural Network#\\nA sequence model is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">usually designed to transform an input sequence into an output sequence that lives in a different domain. Recurrent</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">neural network, short for “RNN”, is suitable for this purpose and has shown tremendous improvement in problems like</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">handwriting recognition, speech recognition, and machine translation (Sutskever et al. 2011, Liwicki et al. 2007).'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'A recurrent neural network model is born with the capability to process long sequential data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and to tackle tasks with context spreading in time. The model processes one element in the sequence at one time </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">step. After computation, the newly updated unit state is passed down to the next time step to facilitate the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">computation of the next element. Imagine the case when an RNN model reads all the Wikipedia articles, character by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">character, and then it can predict the following words given the context.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'A recurrent neural network with one hidden unit (left) and its unrolling version in time </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(right). The unrolling version illustrates what happens in time: $s\\\\_{t-1}$, $s\\\\_{t}$, and $s\\\\_{t+1}$ are the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">same unit with different states at different time steps $t-1$, $t$, and $t+1$. (Image source: LeCun, Bengio, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Hinton, 2015; Fig. 5)'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'However, simple perceptron neurons that linearly combine the current input element and the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">last unit state may easily lose the long-term dependencies. For example, we start a sentence with “Alice is working</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">at …” and later after a whole paragraph, we want to start the next sentence with “She” or “He” correctly. If the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model forgets the character’s name “Alice”, we can never know. To resolve the issue, researchers created a special </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">neuron with a much more complicated internal structure for memorizing long-term context, named “Long-short term </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory (LSTM)” cell. It is smart enough to learn for how long it should memorize the old information, when to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">forget, when to make use of the new data, and how to combine the old memory with new input. This introduction is so</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">well written that I recommend everyone with interest in LSTM to read it. It has been officially promoted in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Tensorflow documentation ;-)'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The structure of a LSTM cell. (Image source: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">http://colah.github.io/posts/2015-08-Understanding-LSTMs)\\n\\nTo demonstrate the power of RNNs, Andrej Karpathy </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">built a character-based language model using RNN with LSTM cells.  Without knowing any English vocabulary </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">beforehand, the model could learn the relationship between characters to form words and then the relationship </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">between words to form sentences. It could achieve a decent performance even without a huge set of training </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">data.\\n\\n\\nA character-based recurrent neural network model writes like a Shakespeare. (Image source: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">http://karpathy.github.io/2015/05/21/rnn-effectiveness)'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'RNN: Sequence-to-Sequence Model#\\nThe sequence-to-sequence model is an extended version of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RNN, but its application field is distinguishable enough that I would like to list it in a separated section. Same </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as RNN, a sequence-to-sequence model operates on sequential data, but particularly it is commonly used to develop </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">chatbots or personal assistants, both generating meaningful response for input questions. A sequence-to-sequence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model consists of two RNNs, encoder and decoder. The encoder learns the contextual information from the input words</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and then hands over the knowledge to the decoder side through a “context vector” (or “thought vector”, as shown in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Fig 8.). Finally, the decoder consumes the context vector and generates proper responses.\\n\\n\\nA </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sequence-to-sequence model for generating Gmail auto replies. (Image source: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://research.googleblog.com/2015/11/computer-respond-to-this-email.html)'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Autoencoders#\\nDifferent from the previous models, autoencoders are for unsupervised </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learning. It is designed to learn a low-dimensional representation of a high-dimensional data set, similar to what </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Principal Components Analysis (PCA) does. The autoencoder model tries to learn an approximation function $ f(x) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\approx x $ to reproduce the input data. However, it is restricted by a bottleneck layer in the middle with a very</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">small number of nodes. With limited capacity, the model is forced to form a very efficient encoding of the data, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that is essentially the low-dimensional code we learned.\\n\\n\\nAn autoencoder model has a bottleneck layer with only</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a few neurons. (Image source: Geoffrey Hinton’s Coursera class \"Neural Networks for Machine Learning\" - Week 15)'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hinton and Salakhutdinov used autoencoders to compress documents on a variety of topics. As </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">shown in Fig 10, when both PCA and autoencoder were applied to reduce the documents onto two dimensions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autoencoder demonstrated a much better outcome. With the help of autoencoder, we can do efficient data compression </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to speed up the information retrieval including both documents and images.\\n\\n\\nThe outputs of PCA (left) and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autoencoder (right) when both try to compress documents into two numbers. (Image source: Hinton &amp; Salakhutdinov </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2006)\\n\\nReinforcement (Deep) Learning#\\nSince I started my post with AlphaGo, let us dig a bit more on why AlphaGo</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">worked out. Reinforcement learning (“RL”) is one of the secrets behind its success. RL is a subfield of machine </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learning which allows machines and software agents to automatically determine the optimal behavior within a given </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context, with a goal to maximize the long-term performance measured by a given metric.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'AlphaGo neural network training pipeline and architecture. (Image source: Silver et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2016)'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The AlphaGo system starts with a supervised learning process to train a fast rollout policy </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and a policy network, relying on the manually curated training dataset of professional players’ games. It learns </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">what is the best strategy given the current position on the game board. Then it applies reinforcement learning by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">setting up self-play games. The RL policy network gets improved when it wins more and more games against previous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">versions of the policy network. In the self-play stage, AlphaGo becomes stronger and stronger by playing against </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">itself without requiring additional external training data.\\nGenerative Adversarial Network#'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Generative adversarial network, short for “GAN”, is a type of deep generative models. GAN is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">able to create new examples after learning through the real data.  It is consist of two models competing against </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">each other in a zero-sum game framework. The famous deep learning researcher Yann LeCun gave it a super high </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">praise: Generative Adversarial Network is the most interesting idea in the last ten years in machine learning. (See</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the Quora question: “What are some recent and potentially upcoming breakthroughs in deep learning?”)'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The architecture of a generative adversarial network. (Image source: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html)'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'In the original GAN paper, GAN was proposed to generate meaningful images after learning from</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">real photos. It comprises two independent models: the Generator and the Discriminator. The generator produces fake </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">images and sends the output to the discriminator model. The discriminator works like a judge, as it is optimized </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for identifying the real photos from the fake ones. The generator model is trying hard to cheat the discriminator </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">while the judge is trying hard not to be cheated. This interesting zero-sum game between these two models motivates</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">both to develop their designed skills and improve their functionalities. Eventually, we take the generator model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for producing new images.\\nToolkits and Libraries#'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'After learning all these models, you may start wondering how you can implement the models and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">use them for real. Fortunately, we have many open source toolkits and libraries for building deep learning models. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Tensorflow is fairly new but has attracted a lot of popularity. It turns out, TensorFlow was the most forked Github</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">project of 2015. All that happened in a period of 2 months after its release in Nov 2015.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'How to Learn?#\\nIf you are very new to the field and willing to devote some time to studying </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">deep learning in a more systematic way, I would recommend you to start with the book Deep Learning by Ian </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Goodfellow, Yoshua Bengio, and Aaron Courville. The Coursera course “Neural Networks for Machine Learning” by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Geoffrey Hinton (Godfather of deep learning!). The content for the course was prepared around 2006, pretty old, but</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">it helps you build up a solid foundation for understanding deep learning models and expedite further </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">exploration.\\nMeanwhile, maintain your curiosity and passion. The field is making progress every day. Even </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">classical or widely adopted deep learning models may just have been proposed 1-2 years ago. Reading academic papers</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can help you learn stuff in depth and keep up with the cutting-edge findings.\\nUseful resources#'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Google Scholar: http://scholar.google.com\\narXiv cs section: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://arxiv.org/list/cs/recent\\nUnsupervised Feature Learning and Deep Learning Tutorial\\nTensorflow </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Tutorials\\nData Science Weekly\\nKDnuggets\\nTons of blog posts and online tutorials\\nRelated Cousera </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">courses\\nawesome-deep-learning-papers\\n\\nBlog posts mentioned#\\n\\nExplained Visually: Image Kernels\\nUnderstanding </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LSTM Networks\\nThe Unreasonable Effectiveness of Recurrent Neural Networks\\nComputer, respond to this </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">email.\\n\\nInteresting blogs worthy of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">checking#\\n\\nwww.wildml.com\\ncolah.github.io\\nkarpathy.github.io\\nblog.openai.com'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Papers mentioned#\\n[1] He, Kaiming, et al. “Deep residual learning for image recognition.” </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Proc. IEEE Conf. on computer vision and pattern recognition. 2016.\\n[2] Wang, Haohan, Bhiksha Raj, and Eric P. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Xing. “On the Origin of Deep Learning.” arXiv preprint arXiv:1702.07800, 2017.\\n[3] Sutskever, Ilya, James Martens,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and Geoffrey E. Hinton. “Generating text with recurrent neural networks.” Proc. of the 28th Intl. Conf. on Machine </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Learning (ICML). 2011.\\n[4] Liwicki, Marcus, et al. “A novel approach to on-line handwriting recognition based on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">bidirectional long short-term memory networks.” Proc. of 9th Intl. Conf. on Document Analysis and Recognition. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2007.\\n[5] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “Deep learning.” Nature 521.7553 (2015): 436-444.\\n[6] </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Hochreiter, Sepp, and Jurgen Schmidhuber. “Long short-term memory.” Neural computation 9.8 (1997): 1735-1780.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2017-06-21-overview/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'[7] Cho, Kyunghyun. et al. “Learning phrase representations using RNN encoder-decoder for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">statistical machine translation.” Proc. Conference on Empirical Methods in Natural Language Processing 1724–1734 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(2014).\\n[8] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. “Reducing the dimensionality of data with neural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">networks.” science 313.5786 (2006): 504-507.\\n[9] Silver, David, et al. “Mastering the game of Go with deep neural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">networks and tree search.” Nature 529.7587 (2016): 484-489.\\n[10] Goodfellow, Ian, et al. “Generative adversarial </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">nets.” NIPS, 2014.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'An Overview of Deep Learning for Curious People\\n    \\nDate: June 21, 2017  |  Estimated \u001b[0m\n",
       "\u001b[32mReading Time: 12 min  |  Author: Lilian Weng'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m(\u001b[0m\u001b[32mThe post was originated from my talk for WiMLDS x Fintech meetup hosted by Affirm.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nI \u001b[0m\n",
       "\u001b[32mbelieve many of you have watched or heard of the games between AlphaGo and professional Go player Lee Sedol in \u001b[0m\n",
       "\u001b[32m2016. Lee has the highest rank of nine dan and many world championships. No doubt, he is one of the best Go players\u001b[0m\n",
       "\u001b[32min the world, but he lost by 1-4 in this series versus AlphaGo. Before this, Go was considered to be an intractable\u001b[0m\n",
       "\u001b[32mgame for computers to master, as its simple rules lay out an exponential number of variations in the board \u001b[0m\n",
       "\u001b[32mpositions, many more than what in Chess. This event surely highlighted 2016 as a big year for AI. Because of \u001b[0m\n",
       "\u001b[32mAlphaGo, much attention has been attracted to the progress of AI.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Meanwhile, many companies are spending resources on pushing the edges of AI applications, \u001b[0m\n",
       "\u001b[32mthat indeed have the potential to change or even revolutionize how we are gonna live. Familiar examples include \u001b[0m\n",
       "\u001b[32mself-driving cars, chatbots, home assistant devices and many others. One of the secret receipts behind the progress\u001b[0m\n",
       "\u001b[32mwe have had in recent years is deep learning.\\nWhy Does Deep Learning Work Now?#\\nDeep learning models, in simple \u001b[0m\n",
       "\u001b[32mwords, are large and deep artificial neural nets. A neural network \u001b[0m\u001b[32m(\u001b[0m\u001b[32m“NN”\u001b[0m\u001b[32m)\u001b[0m\u001b[32m can be well presented in a directed \u001b[0m\n",
       "\u001b[32macyclic graph: the input layer takes in signal vectors; one or multiple hidden layers process the outputs of the \u001b[0m\n",
       "\u001b[32mprevious layer. The initial concept of a neural network can be traced back to more than half a century ago. But why\u001b[0m\n",
       "\u001b[32mdoes it work now? Why do people start talking about them all of a sudden?'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'A three-layer artificial neural network. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: \u001b[0m\n",
       "\u001b[32mhttp://cs231n.github.io/convolutional-networks/#conv\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\nThe reason is surprisingly simple:\\n\\nWe have a lot more \u001b[0m\n",
       "\u001b[32mdata.\\nWe have much powerful computers.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'A large and deep neural network has many more layers + many more nodes in each layer, which \u001b[0m\n",
       "\u001b[32mresults in exponentially many more parameters to tune. Without enough data, we cannot learn parameters efficiently.\u001b[0m\n",
       "\u001b[32mWithout powerful computers, learning would be too slow and insufficient.\\nHere is an interesting plot presenting \u001b[0m\n",
       "\u001b[32mthe relationship between the data scale and the model performance, proposed by Andrew Ng in his “Nuts and Bolts of \u001b[0m\n",
       "\u001b[32mApplying Deep Learning” talk. On a small dataset, traditional algorithms \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRegression, Random Forests, SVM, GBM, \u001b[0m\n",
       "\u001b[32metc.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or statistical learning does a great job, but once the data scale goes up to the sky, the large NN \u001b[0m\n",
       "\u001b[32moutperforms others. Partially because compared to a traditional ML model, a neural network model has many more \u001b[0m\n",
       "\u001b[32mparameters and has the capability to learn complicated nonlinear patterns. Thus we expect the model to pick the \u001b[0m\n",
       "\u001b[32mmost helpful features by itself without too much expert-involved manual feature engineering.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'The data scale versus the model performance. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRecreated based on: \u001b[0m\n",
       "\u001b[32mhttps://youtu.be/F1ka6a13S9I\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Deep Learning Models#\\nNext, let’s go through a few classical deep learning \u001b[0m\n",
       "\u001b[32mmodels.\\nConvolutional Neural Network#'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Convolutional neural networks, short for “CNN”, is a type of feed-forward artificial neural \u001b[0m\n",
       "\u001b[32mnetworks, in which the connectivity pattern between its neurons is inspired by the organization of the visual \u001b[0m\n",
       "\u001b[32mcortex system. The primary visual cortex \u001b[0m\u001b[32m(\u001b[0m\u001b[32mV1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m does edge detection out of the raw visual input from the retina. The \u001b[0m\n",
       "\u001b[32msecondary visual cortex \u001b[0m\u001b[32m(\u001b[0m\u001b[32mV2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, also called prestriate cortex, receives the edge features from V1 and extracts simple\u001b[0m\n",
       "\u001b[32mvisual properties such as orientation, spatial frequency, and color. The visual area V4 handles more complicated \u001b[0m\n",
       "\u001b[32mobject attributes. All the processed visual features flow into the final logic unit, inferior temporal gyrus \u001b[0m\u001b[32m(\u001b[0m\u001b[32mIT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mfor object recognition. The shortcut between V1 and V4 inspires a special type of CNN with connections between \u001b[0m\n",
       "\u001b[32mnon-adjacent layers: Residual Net \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHe, et al. 2016\u001b[0m\u001b[32m)\u001b[0m\u001b[32m containing “Residual Block” which supports some input of one \u001b[0m\n",
       "\u001b[32mlayer to be passed to the component two layers later.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Illustration of the human visual cortex system. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Wang & Raj \u001b[0m\n",
       "\u001b[32m2017\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\nConvolution is a mathematical term, here referring to an operation between two matrices. The convolutional\u001b[0m\n",
       "\u001b[32mlayer has a fixed small matrix defined, also called kernel or filter. As the kernel is sliding, or convolving, \u001b[0m\n",
       "\u001b[32macross the matrix representation of the input image, it is computing the element-wise multiplication of the values \u001b[0m\n",
       "\u001b[32min the kernel matrix and the original image values. Specially designed kernels can process images for common \u001b[0m\n",
       "\u001b[32mpurposes like blurring, sharpening, edge detection and many others, fast and efficiently.\\n\\n\\nThe LeNet \u001b[0m\n",
       "\u001b[32marchitecture consists of two sets of convolutional, activation, and pooling layers, followed by a fully-connected \u001b[0m\n",
       "\u001b[32mlayer, activation, another fully-connected layer, and finally a softmax classifier \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: \u001b[0m\n",
       "\u001b[32mhttp://deeplearning.net/tutorial/lenet.html\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Convolutional and pooling \u001b[0m\u001b[32m(\u001b[0m\u001b[32mor “sub-sampling” in Fig. 4\u001b[0m\u001b[32m)\u001b[0m\u001b[32m layers act like the V1, V2 and V4 \u001b[0m\n",
       "\u001b[32mvisual cortex units, responding to feature extraction. The object recognition reasoning happens in the later \u001b[0m\n",
       "\u001b[32mfully-connected layers which consume the extracted features.\\nRecurrent Neural Network#\\nA sequence model is \u001b[0m\n",
       "\u001b[32musually designed to transform an input sequence into an output sequence that lives in a different domain. Recurrent\u001b[0m\n",
       "\u001b[32mneural network, short for “RNN”, is suitable for this purpose and has shown tremendous improvement in problems like\u001b[0m\n",
       "\u001b[32mhandwriting recognition, speech recognition, and machine translation \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSutskever et al. 2011, Liwicki et al. 2007\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'A recurrent neural network model is born with the capability to process long sequential data \u001b[0m\n",
       "\u001b[32mand to tackle tasks with context spreading in time. The model processes one element in the sequence at one time \u001b[0m\n",
       "\u001b[32mstep. After computation, the newly updated unit state is passed down to the next time step to facilitate the \u001b[0m\n",
       "\u001b[32mcomputation of the next element. Imagine the case when an RNN model reads all the Wikipedia articles, character by \u001b[0m\n",
       "\u001b[32mcharacter, and then it can predict the following words given the context.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'A recurrent neural network with one hidden unit \u001b[0m\u001b[32m(\u001b[0m\u001b[32mleft\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and its unrolling version in time \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mright\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The unrolling version illustrates what happens in time: $s\\\\_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mt-1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m$, $s\\\\_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mt\u001b[0m\u001b[32m}\u001b[0m\u001b[32m$, and $s\\\\_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mt+1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m$ are the \u001b[0m\n",
       "\u001b[32msame unit with different states at different time steps $t-1$, $t$, and $t+1$. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: LeCun, Bengio, and \u001b[0m\n",
       "\u001b[32mHinton, 2015; Fig. 5\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'However, simple perceptron neurons that linearly combine the current input element and the \u001b[0m\n",
       "\u001b[32mlast unit state may easily lose the long-term dependencies. For example, we start a sentence with “Alice is working\u001b[0m\n",
       "\u001b[32mat …” and later after a whole paragraph, we want to start the next sentence with “She” or “He” correctly. If the \u001b[0m\n",
       "\u001b[32mmodel forgets the character’s name “Alice”, we can never know. To resolve the issue, researchers created a special \u001b[0m\n",
       "\u001b[32mneuron with a much more complicated internal structure for memorizing long-term context, named “Long-short term \u001b[0m\n",
       "\u001b[32mmemory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLSTM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m” cell. It is smart enough to learn for how long it should memorize the old information, when to \u001b[0m\n",
       "\u001b[32mforget, when to make use of the new data, and how to combine the old memory with new input. This introduction is so\u001b[0m\n",
       "\u001b[32mwell written that I recommend everyone with interest in LSTM to read it. It has been officially promoted in the \u001b[0m\n",
       "\u001b[32mTensorflow documentation ;-\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'The structure of a LSTM cell. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: \u001b[0m\n",
       "\u001b[32mhttp://colah.github.io/posts/2015-08-Understanding-LSTMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\nTo demonstrate the power of RNNs, Andrej Karpathy \u001b[0m\n",
       "\u001b[32mbuilt a character-based language model using RNN with LSTM cells.  Without knowing any English vocabulary \u001b[0m\n",
       "\u001b[32mbeforehand, the model could learn the relationship between characters to form words and then the relationship \u001b[0m\n",
       "\u001b[32mbetween words to form sentences. It could achieve a decent performance even without a huge set of training \u001b[0m\n",
       "\u001b[32mdata.\\n\\n\\nA character-based recurrent neural network model writes like a Shakespeare. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: \u001b[0m\n",
       "\u001b[32mhttp://karpathy.github.io/2015/05/21/rnn-effectiveness\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'RNN: Sequence-to-Sequence Model#\\nThe sequence-to-sequence model is an extended version of \u001b[0m\n",
       "\u001b[32mRNN, but its application field is distinguishable enough that I would like to list it in a separated section. Same \u001b[0m\n",
       "\u001b[32mas RNN, a sequence-to-sequence model operates on sequential data, but particularly it is commonly used to develop \u001b[0m\n",
       "\u001b[32mchatbots or personal assistants, both generating meaningful response for input questions. A sequence-to-sequence \u001b[0m\n",
       "\u001b[32mmodel consists of two RNNs, encoder and decoder. The encoder learns the contextual information from the input words\u001b[0m\n",
       "\u001b[32mand then hands over the knowledge to the decoder side through a “context vector” \u001b[0m\u001b[32m(\u001b[0m\u001b[32mor “thought vector”, as shown in \u001b[0m\n",
       "\u001b[32mFig 8.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Finally, the decoder consumes the context vector and generates proper responses.\\n\\n\\nA \u001b[0m\n",
       "\u001b[32msequence-to-sequence model for generating Gmail auto replies. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: \u001b[0m\n",
       "\u001b[32mhttps://research.googleblog.com/2015/11/computer-respond-to-this-email.html\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Autoencoders#\\nDifferent from the previous models, autoencoders are for unsupervised \u001b[0m\n",
       "\u001b[32mlearning. It is designed to learn a low-dimensional representation of a high-dimensional data set, similar to what \u001b[0m\n",
       "\u001b[32mPrincipal Components Analysis \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPCA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m does. The autoencoder model tries to learn an approximation function $ f\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32m\\\\approx x $ to reproduce the input data. However, it is restricted by a bottleneck layer in the middle with a very\u001b[0m\n",
       "\u001b[32msmall number of nodes. With limited capacity, the model is forced to form a very efficient encoding of the data, \u001b[0m\n",
       "\u001b[32mthat is essentially the low-dimensional code we learned.\\n\\n\\nAn autoencoder model has a bottleneck layer with only\u001b[0m\n",
       "\u001b[32ma few neurons. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Geoffrey Hinton’s Coursera class \"Neural Networks for Machine Learning\" - Week 15\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Hinton and Salakhutdinov used autoencoders to compress documents on a variety of topics. As \u001b[0m\n",
       "\u001b[32mshown in Fig 10, when both PCA and autoencoder were applied to reduce the documents onto two dimensions, \u001b[0m\n",
       "\u001b[32mautoencoder demonstrated a much better outcome. With the help of autoencoder, we can do efficient data compression \u001b[0m\n",
       "\u001b[32mto speed up the information retrieval including both documents and images.\\n\\n\\nThe outputs of PCA \u001b[0m\u001b[32m(\u001b[0m\u001b[32mleft\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and \u001b[0m\n",
       "\u001b[32mautoencoder \u001b[0m\u001b[32m(\u001b[0m\u001b[32mright\u001b[0m\u001b[32m)\u001b[0m\u001b[32m when both try to compress documents into two numbers. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Hinton & Salakhutdinov \u001b[0m\n",
       "\u001b[32m2006\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\nReinforcement \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDeep\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Learning#\\nSince I started my post with AlphaGo, let us dig a bit more on why AlphaGo\u001b[0m\n",
       "\u001b[32mworked out. Reinforcement learning \u001b[0m\u001b[32m(\u001b[0m\u001b[32m“RL”\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is one of the secrets behind its success. RL is a subfield of machine \u001b[0m\n",
       "\u001b[32mlearning which allows machines and software agents to automatically determine the optimal behavior within a given \u001b[0m\n",
       "\u001b[32mcontext, with a goal to maximize the long-term performance measured by a given metric.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'AlphaGo neural network training pipeline and architecture. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Silver et al. \u001b[0m\n",
       "\u001b[32m2016\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'The AlphaGo system starts with a supervised learning process to train a fast rollout policy \u001b[0m\n",
       "\u001b[32mand a policy network, relying on the manually curated training dataset of professional players’ games. It learns \u001b[0m\n",
       "\u001b[32mwhat is the best strategy given the current position on the game board. Then it applies reinforcement learning by \u001b[0m\n",
       "\u001b[32msetting up self-play games. The RL policy network gets improved when it wins more and more games against previous \u001b[0m\n",
       "\u001b[32mversions of the policy network. In the self-play stage, AlphaGo becomes stronger and stronger by playing against \u001b[0m\n",
       "\u001b[32mitself without requiring additional external training data.\\nGenerative Adversarial Network#'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Generative adversarial network, short for “GAN”, is a type of deep generative models. GAN is \u001b[0m\n",
       "\u001b[32mable to create new examples after learning through the real data.  It is consist of two models competing against \u001b[0m\n",
       "\u001b[32meach other in a zero-sum game framework. The famous deep learning researcher Yann LeCun gave it a super high \u001b[0m\n",
       "\u001b[32mpraise: Generative Adversarial Network is the most interesting idea in the last ten years in machine learning. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSee\u001b[0m\n",
       "\u001b[32mthe Quora question: “What are some recent and potentially upcoming breakthroughs in deep learning?”\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'The architecture of a generative adversarial network. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: \u001b[0m\n",
       "\u001b[32mhttp://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'In the original GAN paper, GAN was proposed to generate meaningful images after learning from\u001b[0m\n",
       "\u001b[32mreal photos. It comprises two independent models: the Generator and the Discriminator. The generator produces fake \u001b[0m\n",
       "\u001b[32mimages and sends the output to the discriminator model. The discriminator works like a judge, as it is optimized \u001b[0m\n",
       "\u001b[32mfor identifying the real photos from the fake ones. The generator model is trying hard to cheat the discriminator \u001b[0m\n",
       "\u001b[32mwhile the judge is trying hard not to be cheated. This interesting zero-sum game between these two models motivates\u001b[0m\n",
       "\u001b[32mboth to develop their designed skills and improve their functionalities. Eventually, we take the generator model \u001b[0m\n",
       "\u001b[32mfor producing new images.\\nToolkits and Libraries#'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'After learning all these models, you may start wondering how you can implement the models and\u001b[0m\n",
       "\u001b[32muse them for real. Fortunately, we have many open source toolkits and libraries for building deep learning models. \u001b[0m\n",
       "\u001b[32mTensorflow is fairly new but has attracted a lot of popularity. It turns out, TensorFlow was the most forked Github\u001b[0m\n",
       "\u001b[32mproject of 2015. All that happened in a period of 2 months after its release in Nov 2015.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'How to Learn?#\\nIf you are very new to the field and willing to devote some time to studying \u001b[0m\n",
       "\u001b[32mdeep learning in a more systematic way, I would recommend you to start with the book Deep Learning by Ian \u001b[0m\n",
       "\u001b[32mGoodfellow, Yoshua Bengio, and Aaron Courville. The Coursera course “Neural Networks for Machine Learning” by \u001b[0m\n",
       "\u001b[32mGeoffrey Hinton \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGodfather of deep learning!\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The content for the course was prepared around 2006, pretty old, but\u001b[0m\n",
       "\u001b[32mit helps you build up a solid foundation for understanding deep learning models and expedite further \u001b[0m\n",
       "\u001b[32mexploration.\\nMeanwhile, maintain your curiosity and passion. The field is making progress every day. Even \u001b[0m\n",
       "\u001b[32mclassical or widely adopted deep learning models may just have been proposed 1-2 years ago. Reading academic papers\u001b[0m\n",
       "\u001b[32mcan help you learn stuff in depth and keep up with the cutting-edge findings.\\nUseful resources#'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Google Scholar: http://scholar.google.com\\narXiv cs section: \u001b[0m\n",
       "\u001b[32mhttps://arxiv.org/list/cs/recent\\nUnsupervised Feature Learning and Deep Learning Tutorial\\nTensorflow \u001b[0m\n",
       "\u001b[32mTutorials\\nData Science Weekly\\nKDnuggets\\nTons of blog posts and online tutorials\\nRelated Cousera \u001b[0m\n",
       "\u001b[32mcourses\\nawesome-deep-learning-papers\\n\\nBlog posts mentioned#\\n\\nExplained Visually: Image Kernels\\nUnderstanding \u001b[0m\n",
       "\u001b[32mLSTM Networks\\nThe Unreasonable Effectiveness of Recurrent Neural Networks\\nComputer, respond to this \u001b[0m\n",
       "\u001b[32memail.\\n\\nInteresting blogs worthy of \u001b[0m\n",
       "\u001b[32mchecking#\\n\\nwww.wildml.com\\ncolah.github.io\\nkarpathy.github.io\\nblog.openai.com'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Papers mentioned#\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m He, Kaiming, et al. “Deep residual learning for image recognition.” \u001b[0m\n",
       "\u001b[32mProc. IEEE Conf. on computer vision and pattern recognition. 2016.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Wang, Haohan, Bhiksha Raj, and Eric P. \u001b[0m\n",
       "\u001b[32mXing. “On the Origin of Deep Learning.” arXiv preprint arXiv:1702.07800, 2017.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m3\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Sutskever, Ilya, James Martens,\u001b[0m\n",
       "\u001b[32mand Geoffrey E. Hinton. “Generating text with recurrent neural networks.” Proc. of the 28th Intl. Conf. on Machine \u001b[0m\n",
       "\u001b[32mLearning \u001b[0m\u001b[32m(\u001b[0m\u001b[32mICML\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. 2011.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Liwicki, Marcus, et al. “A novel approach to on-line handwriting recognition based on \u001b[0m\n",
       "\u001b[32mbidirectional long short-term memory networks.” Proc. of 9th Intl. Conf. on Document Analysis and Recognition. \u001b[0m\n",
       "\u001b[32m2007.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “Deep learning.” Nature 521.7553 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2015\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: 436-444.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mHochreiter, Sepp, and Jurgen Schmidhuber. “Long short-term memory.” Neural computation 9.8 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1997\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: 1735-1780.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2017-06-21-overview/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Cho, Kyunghyun. et al. “Learning phrase representations using RNN encoder-decoder for \u001b[0m\n",
       "\u001b[32mstatistical machine translation.” Proc. Conference on Empirical Methods in Natural Language Processing 1724–1734 \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32m2014\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m8\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. “Reducing the dimensionality of data with neural \u001b[0m\n",
       "\u001b[32mnetworks.” science 313.5786 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2006\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: 504-507.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Silver, David, et al. “Mastering the game of Go with deep neural \u001b[0m\n",
       "\u001b[32mnetworks and tree search.” Nature 529.7587 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2016\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: 484-489.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m10\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Goodfellow, Ian, et al. “Generative adversarial \u001b[0m\n",
       "\u001b[32mnets.” NIPS, 2014.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load, chunk and index the contents of the blog.\n",
    "import bs4\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2017-06-21-overview/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(splits)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    base_url=\"https://models.inference.ai.azure.com\",\n",
    "    api_key=token,\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ef80f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'lc_hub_owner'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'rlm'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'lc_hub_repo'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'rag-prompt'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'lc_hub_commit_hash'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessagePromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'question'</span><span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"You are an assistant for question-answering tasks. Use the following pieces of retrieved </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'context'\u001b[0m, \u001b[32m'question'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'lc_hub_owner'\u001b[0m: \u001b[32m'rlm'\u001b[0m,\n",
       "        \u001b[32m'lc_hub_repo'\u001b[0m: \u001b[32m'rag-prompt'\u001b[0m,\n",
       "        \u001b[32m'lc_hub_commit_hash'\u001b[0m: \u001b[32m'50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mHumanMessagePromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mprompt\u001b[0m=\u001b[1;35mPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'context'\u001b[0m, \u001b[32m'question'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mtemplate\u001b[0m=\u001b[32m\"You\u001b[0m\u001b[32m are an assistant for question-answering tasks. Use the following pieces of retrieved \u001b[0m\n",
       "\u001b[32mcontext to answer the question. If you don't know the answer, just say that you don't know. Use three sentences \u001b[0m\n",
       "\u001b[32mmaximum and keep the answer concise.\\nQuestion: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\nContext: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\nAnswer:\"\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65e8af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e18ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52e7ef16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Convolutional Neural Networks (CNNs) are a type of feed-forward artificial neural network inspired by the organization of the visual cortex. They use convolutional layers with kernels or filters that slide across input images to detect features like edges and patterns. CNNs are widely used for image recognition and processing tasks.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Convolutional Neural Networks?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
